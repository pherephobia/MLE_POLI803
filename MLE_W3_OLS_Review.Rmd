---
title: "POLI803: Maximum Likelihood Estimation"
subtitle: "Week 3: OLS Regression Review"
author: "Ph.D. Student, Sanghoon Park (Univ. of South Carolina)"
date: "9/11/2019"
header-includes:
  - \usepackage{kotex}
output: 
  pdf_document: 
    latex_engine: xelatex
    fig_height: 6
    fig_width: 10
    toc: no
  html_document:
    fig_height: 6
    fig_width: 10
    highlight: textmate
    theme: cosmo
    toc: yes
    toc_depth: 3
    toc_float: yes
  word_document:
    fig_height: 6
    fig_width: 9
    toc: no
html_notebook: default
html_document: default
mainfont: NanumGothic
urlcolor: blue
---

```{r setup, include = FALSE, echo = FALSE}
knitr::opts_chunk$set(error = TRUE, warning = FALSE, message = FALSE)
```

이번에는 데이터를 효율적으로, 그리고 체계적으로 전처리하는 방법에 대해서 살펴볼 것이다. 앞서 언급한 바와 같이 전처리 및 데이터 관리를 위해서 `tidyverse` 패키지와 그 패키지에 속하는 다른 패키지들(`tidyverse familiy`), 그리고 함수들을 주로 사용할 것이다.

# 패키지 불러오기

```{r}
library(tidyverse)  # 데이터 관리 및 전처리를 위한 주요 패키지
library(ezpickr)    # 다른 확장자의 파일을 R로 불러오기 위한 패키지
library(here)       # 현재 작업디렉토리를 R-스크립트가 위치한 디렉토리로 자동설정하는 패키지
library(lubridate)  # 날짜시각 데이터를 원활하게 가공하는 데 특화된 패키지
```

들어가기에 앞서서 간단한 기본 함수들을 다시 리뷰해보자.

```{r}
x <- 10
add_one <- function(x) x + 10
add_one(5) # 결과가 15일까, 20일까?
```

자칫하면 위의 함수에서 `x <- 10`으로 `x`라는 객체에 10을 넣었기 때문에 `10 + 10`이 되어 결과를 20으로 리턴할 것이라고 생각할 수 있다. 하지만 어디까지나 `add_one` 함수가 정의되고 난 이후, `x`는 `add_one()`의 괄호 안에 들어가는 값으로 재정의되었다. 따라서 5를 `add_one()`에 투입한 순간, 그 함수는 `5 + 10`을 계산하게 된 것이다. 따라서 결과는 15가 된다.

```{r, error = TRUE}
new_add_one <- function(x) x + 10 # 그렇다면 이 경우는 어떨까?
new_add_one() 
```

이번에는 `new_add_one()` 함수를 정의하고, x 값을 따로 주지 않고 빈 함수를 작동시켰다. 이때, `new_add_one()`은 주어진 투입값(input)이 없기 때문에, 함수에 요구되는 `x`를 찾기 위해 함수 안에서 `x`를 탐색하는 것을 넘어서 한 단계 위에서 `x`를 찾는다. 바로 처음에 만든 `x <- 10`을 불러오는 것이다. 따라서 `10 + 10`, 20을 출력하게 된다.

함수와 객체의 관계에 대해 다시 한 번 살펴보자.
```{r, error = TRUE}
print_hello_world <- function() {
  z <- "Hello, world"
  print(z)
}

print_hello_world()
print(z)
```
`print_hello_world()` 함수를 작동시키면 함수 내에서 정의된 객체 `z`의 값을 반환한다. 그렇지만 그 `z`는 어디까지나 함수 내에서만 정의된 것이지 **R**의 글로벌 환경에 저장된 객체는 아니다. 따라서 함수 내에서 정의된 `z`를 출력하라고 명령하면, 오류 코드를 확인하게 된다.

**R**에서 객체를 제외하고 작동하는 모든 기능들은 '함수'라고 부른다. 그리고 함수는 같은 결과를 다른 방식으로 출력할 수도 있다.

```{r, error = TRUE}
5 + 5     # 간단하게 말하자면 이 함수(+)는
`+`(5, 5) # 이런 식으로도 쓸 수 있다.
```

또한, 기존에 **R**에는 내장되지 않았던 함수도 별도로 특정하게 지정하여 만들 수 있다. 그러나 이 경우에는 별도의 패키지로 만들어서 저장해주지 않는 한, **R** 코드가 작성된 해당 세션에서만 지속되는 함수일 뿐이다.

아래는 문자열과 문자열을 하나로 합치고 있은데, 일반적으로 두 객체를 합칠 때 쓰는 함수인 `+`는 숫자형 객체 간에만 기능한다. 따라서 문자열끼리 합쳐주는 함수, `paste()`와 동일한 기능을 하는 별도의 함수 기호를 하나 만들어주고자 한다.

```{r, error = TRUE}
print("hello" + "world") # 오류메시지를 확인할 수 있다. +는 숫자형 객체들에만 작동한다.
paste("hello ", "world")
`%+%` <- function(lhs, rhs) paste0(lhs, rhs)
print("hello " %+% "world")
```

이제 패키지를 불러오는 작업과 간단한 함수, 그리고 객체의 특성에 대해 리뷰했으니 다음으로 넘어가 보자.

# 작업 디렉토리 설정하기

아까 불러온 `here` 패키지의 `here()` 함수를 사용할 수 있다. `here()`를 사용하면 자동으로 현재 R-스크립트가 저장된 경로를 확인, 복사한다. `%>%`는 파이프 왼쪽의 기능 이후에 오른쪽의 기능을 적용시키는 지정된 함수로 `tidyverse` 패키지가 가지고 있는 강점 중 하나이다. 

이 파이프 함수를 이용하여 우리는 코드를 보다 논리적으로, 그리고 정연하게 작성하여 가독성을 높일 수 있다.

```{r, eval = FALSE}
here() %>% setwd() # here()로 R-스크립트의 디렉토리를 확인하고 난 다음에
                   # 그 디렉토리로 작업 디렉토리를 설정(set working directory, setwd)하라는
                   # 함수를 작동시킨 것이다.
```

```{r}
## 이렇게 작업 디렉토리를 설정하였다면, 이제 데이터를 불ㄹ오자.: diamond_data를 사용한다.
df <- pick("example_data/diamonds_data.xlsx") # pick() 함수는 ezpickr 패키지에 속해 있다.
## ezpickr는 여러 유형의 자료를 Hadley Wickam이 개발한 신뢰할 수 있는 여러 패키지들의 
## 함수와 연동하여 tibble의 형태로 사용할 수 있도록 도와준다.
typeof(df)
```

# 데이터 전처리 하기(Data Cleaning)

## `dplyr` 패키지를 이용한 데이터 전처리

### 데이터를 들여다보고, 결측치를 확인하기
```{r}
nrow(df)   # 데이터의 행의 개수를 확인하는 함수이다.
ncol(df)   # 데이터의 열의 개수를 확인하는 함수이다.
length(df) # 데이터에 속한 관측치의 개수를 확인하는 함수이다.

# 기본적으로 R에 내장된 함수들을 이용하여 변수를 만들고 목록화하기(indexing)
df$index <- 1:nrow(df) # index라는 새로운 변수를 만들고 행의 수로 연번 매기기
head(df)               # 맨 위의 몇 개 행을 보여준다. 
glimpse(df)            # 데이터의 구조를 깔끔하게 보여주는 함수이다.
```

#### 데이터를 좀 더 자세하게 들여다보기

```{r}
df # 이미 ezpickr로 불러와서 자료유형은 tibble이다.
print(df, n = 12) # tibble 유형의 데이터 df의 첫 12개 행을 보여준다.
df %>% slice(nrow(df) - 5:nrow(df))  # 마지막 5개 행을 제외한 행을 보여준다.
df %>% slice(nrow(df):12)            # 뒤에서부터 12개 행을 보여준다.
df %>% slice(c(1, 7, 54))            # 원하는 행만을 보여준다.
```

#### 결측치 확인하기

데이터 안에 결측치(NA, missing data)가 몇 개나 있는지를 확인하는 것은 중요하다. 실제로 통계분석을 수행할 때에는 변수에 결측치가 하나라도 존재하면 최종 모형에서 그 결측치가 속한 행 전체는 분석에서 제외된다. 따라서 분석 모형에 있어서 표본의 수(sample size)라는 측면에서 생각해볼 때, 전체 관측치의 개수만큼이나 결측치가 얼마나 되는 것을 파악하는 것도 중요하다.

```{r}
sum(is.na(df)) # 결측치의 수를 계산하는 함수
df %>% is.na() %>% sum() # 위와 동일한 함수.
```

`df`라는 tibble 을 가지고 `is.na()`, 즉 `df` 중 `NA`인 것들만 골라서 `sum()`으로 더하라는 코드다.

  + 파이프 함수에서 `()`의 빈괄호는 앞의 데이터를 그대로 받아넘기는 기능이다.
  + 그리고 `is.na()` 함수는 논리형으로 "`()`에 들어간 객체에 결측치가 있는가?"를 묻는다.
  + 결측치가 있으면 `TRUE`, 없으면 `FALSE`로 나올 것이고, **R**에서 `TRUE = 1`, `FALSE = 0`이다.
  + 그렇게 나온 `TRUE`들의 총합을 구하면 `df`라는 데이터 안의 결측치의 총 개수를 확인할 수 있다.
    
    + 그렇다면 왜 총합을 구하는 함수 내에 `na.rm = T`라는 옵션을 사용하지 않은 것일까?
    + 보통 **R**에서 `sum()` 함수는 그 객체에 결측치가 하나라도 있으면 전체 계산을 `NA`로 반환한다.
    + 그러나 이 경우에서는 파이프를 통해서 `df`에서 결측치/관측치를 각각 1, 0으로 변환시켰기 때문에 
    + 더 이상 결측치도 missing data, `NA`가 아닌 숫자형으로 간주되기 때문에 바로 더할 수 있다.

그렇다면 이제는 각 열마다 (변수마다) 관측치가 몇이나 있는지를 확인해보자.

```{r}
df %>% map_int( function(x) is.na(x) %>% sum() %>% as.integer() )
## df를 map_int 함수로 넘기되, 이 함수는 만약 x라는 객체가 관측치이거든 총합을 구해 그 결과를
## 정수형(integer)로 반환하라는 코드이다.
## 즉, 이 경우 df에 관측치가 있으면 그 관측치의 총합을 더하여 숫자로 바꾼 결과를 출력할 것이다.
## 변수별로 관측치의 개수를 확인할 수 있다.
df %>% map_dbl( function(x) is.na(x) %>% sum() ) # 위와 동일하지만 double 유형의 데이터로 반환한다.
typeof(df %>% map_int( function(x) is.na(x) %>% sum() %>% as.integer() )) # 자료유형 integer
typeof(df %>% map_dbl( function(x) is.na(x) %>% sum() ))                  # 자료유형 double

## 만약 변수명을 따로 보기 싫다면? unname() 함수 추가
df %>% map_int( function(x) is.na(x) %>% sum() %>% as.integer() ) %>% unname()

```

`unname()` 함수에 대해 조금 더 알아보자.

```{r}
c(one = 1, two = 2, three = 3)         # 벡터 객체는 값에 라벨링을 할 수 있다.
unname(c(one = 1, two = 2, three = 3)) # unname()을 사용하면 그 라벨링을 제외한 순수한 요소의
                                       # 값만을 확인할 수 있다.
```

특정 벡터 내에 결측치의 개수가 몇 개인지를 구하는 코드를 하나의 함수로 다시 만들어서 함수 객체의 형태로 저장하자.

```{r}
get_number_of_missings_in_vector <- function(some_vector) {
  result <- some_vector %>%
    is.na() %>%
    sum() %>%
    as.integer()
  return(result)
}
get_number_of_missings_in_vector(df)
```

`get_number_of_missings_in_vector()` 함수는 아까 위의 함수(주어진 객체의 결측치 확인, 총합 계산, 정수형 반환)를 `result`라는 객체에 저장하고 반환하라는 코드를 내장하고 있다. 따라서 우리는 앞서와 마찬가지로 `df`에 결측치가 없다는 0을 반환하게 된다.

앞서 말했다시피 데이터프레임과 같은 형식의 자료에 `NA`가 있으면, **R**은 결측치를 제외할 때, 측치가 속한 행을 아예 삭제해버린다.

```{r}
df %>% na.omit()
```

**중요한 점은 R은 단지 함수적인 프로그래밍 언어이기 때문에 그 결측치를 제거한 이후에 별도로 저장해주지 않으면 다시 불러오는 객체 `df`는 결측치가 제거되지 않은 원래의 형태로 다시 불려오게 된다. 즉, `new_df <- df %>% na.omit()`와 같은 식으로 재저장 해주어야만 결측치가 제거된 데이터를 가지게 된다.**

데이터에 결측치가 있을 때, 그 결측치들을 제외하게 되면 어떻게 되는지 한 번 아래의 예제 코드로 확인해보자.

```{r}
example <- matrix(c(1, 2, 3, NA), nrow = 2, byrow = T) %>%
  as.data.frame()
example %>% na.omit()
example  # 결측치를 제거한 example 데이터를 재저장 하지 않았기 때문에 결측치가 그대로 남아있다.
example <- example %>% na.omit()
example  # 결측치가 제거되어 있는 것을 확인할 수 있다.
```

**한 가지 강조할 것은 모든 `dplyr` 함수는 (아마 거의 모든 tidyverse 함수들은) 첫 번째로 데이터를 지정하여 파이프로 넘기면 그 이후의 파이프들은 맨 처음의 데이터를 그대로 가지고 후속 함수들을 그 데이터에 순차적으로 적용하는 과정을 거치게 된다.**


### `dplyr`패키지의 주요 함수들

#### `dplyr::filter()`: 필터 함수

`dplyr::filter()` 함수는 `()` 안에 설정하는 조건문에 따라서 관측치를 필터링한다. 이때, 조건문은 논리형 연산자로 기능하는데, 조건에 따라 투입값이 참(`TRUE`)인지 거짓(`FALSE`)인지 반환한다. **R**에는 `dplyr` 패키지 말고도 다른 `filter()` 함수를 가지고 있기 때문에 `::`의 로딩 함수를 가지고 `dplyr` 패키지의 `filter()` 함수를 직접 불러오는 것이 확실하다.

```{r}
## df 데이터의 cut이라는 변수가 Ideal이라는 값을 가질 경우만 보여주어라.
df %>% dplyr::filter(cut == "Ideal")  
df %>% dplyr::filter(cut %in% c("Ideal", "Premium")) # 조건을 여러 개 걸 수도 있다.
## %in% 함수는 우측에 지정한 객체가 좌측에 포함되어 있냐는 것을 묻는 논리형의 기능을 수행한다.

## %in% 함수를 자세히 알아보자.
names_ <- c("Sara", "Robert", "James") # names_라는 객체에 세 이름이 있을 때, 
"James" %in% names_                    # names_안에 James라는 이름이 있으면?
```

#### `dplyr::select()`: 선택 함수

`dplyr::select()` 함수는 데이터 안에서 특정한 변수만을 선택하고자 할 때 사용할 수 있다. 데이터를 관리하고 전처리를 할 때 굉장히 유용하게 사용할 수 있는 함수이다. 예를 들어, World Development Indicators에서 전체 변수 중 필요한 변수만을 선택하여 새로운 데이터로 재지정할 수 있는 것이다.

```{r}
df %>% select(carat, color, x)            # df 데이터 중 carat ,color, x 변수만 뽑아내라.
df %>% select(-carat, -color, x)          # carat과 color를 제외한 나머지 변수들만 뽑아내라.
df %>% select(depth, price, everything()) # 변수의 순서 정리: depth, price, 나머지는 그대로.
df %>% select_if(is.character)            # 문자열인 변수들만 남겨라.
```

위의 예제에서 눈여겨볼 만한 것은 바로 세 번째 `select()` 함수 내에서 작동하는 `everything()`함수와 `select_if()`라는 변형 함수이다.

  + 만약 `everything()` 함수가 없었다면 변수들의 이름을 줄줄이 나열해야 해서 `select()` 함수의 효용이 많이 떨어졌을 것이다.
  + 그리고 `select_if()`는 조건문을 반영할 수 있다.
  + `-`를 통해서 변수를 제외하는 여집합적 구성도 가능하다(`carat`과 `color`만 제외하는 것처럼)
  
`select()` 함수를 조금 더 자세하게 알아보자.

```{r}
## 인덱싱 기능을 이용하여 열번(number of columns)을 이용해 select()를 활용해보자.
df %>% select(1:3)         # 첫 번째부터 세 번째 변수만을 선택해 뽑아내라.
df %>% select(-c(1, 2, 6)) # 첫 번째, 두 번째, 여섯 번째 변수를 제외하고 나머지를 뽑아내라.

## select() 함수는 범용성이 높다. 변수명이 어떤 글자로 시작하는지, 끝나는지, 
## 혹은 어떤 글자를 포함하는지에 따라서도 select()를 적용하여 변수를 뽑아낼 수 있다.
df %>% select(starts_with("c"))
df %>% select(ends_with("y"))
df %>% select(contains("olo"))

## 마찬가지로 제외하는 함수(-)도 적용된다.
df %>% select(-contains("olo"))
```

`select()` 함수를 이용해서 변수를 선택-추출해내는 것 외에도 변수 이름을 변경하는 것도 가능하다. 단, 이때 `everything()` 함수를 지정해주는 것을 잊엇는 안 된다. 왜냐하면 `everything()` 없이 변수명만 바꿔버리면 `select()`는 바꾼 그 변수들만을 출력하고 나머지 변수들은 제외해버리기 때문이다.

물론 그렇게 `select()` 함수를 적용하고 별도로 저장하지 않으면 `df` 자체에는 변화가 없기 때문에 다시 `everything()`을 추가해서 코드를 작동시키고 다른 객체로 저장하면 된다.

  + 그러면 바뀐 변수 + 바꾸지 않은 다른 변수들이 `new_df` 라던지 다른 객체 이름으로 저장될 것이다.
  + 그리고 이때, 바뀐 함수들이 먼저 오고 그 다음으로 다른 변수들이 순서대로 붙게 된다.

```{r}
df %>% select(new_depth = depth, new_color = color, everything())  # 새 변수 + 기존 변수
df %>% select(everything(), new_depth = depth, new_color = color)  # 기존 변수 + 새 변수

## select()로도 변수명을 바꿀 수 있지만, rename()을 이용하면 굳이 everything() 안쓰고도
## 간단하게 할 수 있다. 역시 편법은 쓰는 게 아니다.
df %>% rename(new_depth = depth, new_color = color)

## 한 번에 모든 변수들의 이름을 일괄적으로 변경하기
df %>% rename_all(function(x) str_c(x, "_new"))
df %>% rename_all(function(x) str_to_upper(x))

## 특정한 조건을 가진 변수들만 이름을 변경하기rename only certain variables
df %>% rename_at(             # rename_at()으로 조건을 특정한다.
  vars( starts_with("c") ),   # 변수들을 대상으로 하되, "c"로 변수명이 시작하는
  function(x) str_to_upper(x) # 어떻게 바꾼다? 모두 변수명을 대문자로 바꾼다.
)

## rename_if() 함수를 이용하면 특정 조건을 충족하는 변수들의 이름을 변경할 수 있다.
df %>% rename_if( is.numeric, str_to_upper ) # 숫자형인 변수들의 이름을 대문자로 바꿔라.
## 이 경우 문자형 값을 가지는 color, cut 등은 변수명이 바뀌지 않는 것을 확인할 수 있다.
```

#### `dplyr::mutate()`: 변수 조작 함수

`dplyr::mutate()`는 데이터 전처리 및 관리에서 가장 요긴하게 쓰일 함수이다. 이 함수는 새로운 변수를 만들거나 기존 변수에 조작을 가할 때 사용한다.

```{r, error = TRUE}
df %>% mutate(carat_multiplied = carat * 10) # 기존 carat 변수에 10배가 된 값을 가진 
                                             # 새로운 변수 carat_multiplied를 만들어라.
df %>% mutate(carat = carat * 10)            # 기존 carat 변수의 값에 10배를 곱하라.

## 첫 번째 코딩과 두 번째 코딩의 차이점은 첫 번째 코딩은 기존 변수를 이용해
## 새 변수를 만든 것이고, 두 번째 코딩은 기존 변수 자체의 값을 바꾸어 버린 것이다.
```

하나의 `mutate()` 함수 내부에 여러 줄의 멀티코드를 통해서 순서대로 변수를 조작할 수 있다.

```{r}
df %>% select(carat) %>%
  mutate(
    caret_times_2 = carat * 2,
    caret_times_2_times_2 = caret_times_2 * 2,
    caret_times_2_times_2_times_3 = caret_times_2_times_2 * 3
  )

## mutate() 함수 역시 _at, _all, _if의 세부함수를 가진다.
df %>% mutate_if(is.character, factor)  # 변수가 문자형이거든 요인형으로 바꾸어라.
df %>% mutate_at(vars( color, clarity ), factor) # color, clarity 변수를 요인형으로 바꾸어라.
df %>% mutate_all(as.character) # 모든 변수들을 문자형으로 바꾸어라.
```


#### 다른 `dplyr` 패키지의 유용한 함수들

##### `arrange()`: 변수의 값을 정렬할 때 쓰는 함수이다.

`df` 데이터에서 `price`라는 함수 + 나머지 다른 함수로 순서를 재정리하고, 그 다음에 `price`를 기준으로 변수를 정렬해보도록 하겠다. `arrange()`의 디폴트 값은 오름차순이다. 

내림차순으로 바꾸고 싶으면 `desc()` 함수를 사용하면 된다.
```{r}
df %>% select(price, everything()) %>% arrange(price) # price 기준으로 오름차순 정렬
df %>% select(price, everything()) %>% arrange(desc(price)) # price 기준 내림차순 ㅈㅇ렬
df %>% arrange(color, cut, desc(price))  # color, cut을 맨 앞으로 빼고 전체 변수는
                                         # price 기준으로 내림차순 정렬
## 바로 위의 코딩은 관심있는 주요 변수를 맨 앞으로 빼고 주요 변수들이 다른 변수(price)의
## 크기에 따라 어떻게 나타나는지를 파악할 수 있게 해주는 코드이다.
## select() 사용하지 않고 바로 arrange()를 적용하였다.
## 예를 들어, 정치체제(민주주의/비민주주의) 변수를 앞으로 빼고 정렬 기준을 GDPpc 로 하는 등
## 응용이 가능하다.
```

##### `group_by()`: 집단별 묶음

`group_by()`를 쓰면 함수 내의 같은 변수값별로 묶인 결과를 보여준다. 숫자형, 문자형 모두 적용된다. 즉, 만약 `group_by(price)`로 하면 변수들이 같은 가격별로 묶여서 보일 것이고, 아래와 같이 `group_by(cut)`을 한다면 다이아몬드 컷팅 유형별로 분류해서 보여준다.

유의할 점은 먼저 `group_by()`를 지정해주고 그 이후에 다른 함수를 사용하면 집단별로 묶인 상태에서 그 함수들이 순차적으로 적용된다는 점이다. `group_by()`를 사용했을 때와 그렇지 않을 때를 구분해보자. 내림차순된 가격 변수를 기준으로 첫째 행과 둘째 행, 즉 가장 비싼 가격과 두 번째로 비싼 가격만을 잘라서(`slice(1 : 2)`) 보여주라는 명령어이다.

```{r}
df %>% group_by(cut) %>%     # df의 cut 변수 유형별로 묶은 것이다.
  arrange(desc(price)) %>%   # 그렇게 묶인 데이터가 파이프로 넘어가고, 가격 기준 내림차순 정렬
  slice(1 : 2)               # 컷팅 유형별 + 가격 기준 내림차순 중 첫 두 행만 보여주라는 코드

## group_by()를 사용하지 않았을 때와 비교해보자.
df %>% arrange(desc(price)) %>% slice(1:2)
## 이 경우는 전체 df 데이터에서 가격 순으로 1, 2위의 값만 갖게 된다.
## cut 변수는 반영되지 않는다.
```

한 가지 유의해야할 점은 티블 유형에 `group_by()`를 적용할 경우 그 결과가 일반 티블과는 다른 특성을 가지게 된다는 것이다.

```{r}
df_group <- df %>% group_by(cut) %>%
  arrange(desc(price)) %>%
  slice(1:2)
class(df_group)
df_group
```

보면 "`grouped_df`"라는 특성이 추가된 것을 확인할 수 있다. 티블과 `group_by()`를 함께 쓸 때는 `ungroup()` 함수를 같이 사용할 것을 추천하는데, 이는 다음과 같은 이유에서이다.

1. 미리 언급한 바와 같이 `grouped_`라는 속성이 생김으로써, `group_by()`가 야기할 수 있는 잠재적인 오류를 피하기 위해서다.

2. `ungroup()` 함수를 이용하여 파이프 함수로 구성된 코드가 `group_by()` 함수가 적용된 것임을 명시적으로 줄 수 있다. 따라서 우리는 `ungroup()` 함수가 코드에 포함되어 있다면 해당 티블이 그룹핑된 결과일 수 있다고 바로 알 수 있다. 단적으로 코드의 가독성과 명확성이 좋아진다.

3. 글로벌 환경을 `.Rdata` 객체로 저장하여 불러오거나 할 때, `group_by()` 해놓고 `ungroup()` 안하면 기록은 남아있지 않는데 해당 티블에 `grouped_` 속성이 남아 추후 분석에 어려움이 있을 수 있다.

```{r}
## 따라서 ungroup()을 이용하여 일반적인 티블로 다시 바꿔준다.
df_group <- df %>% group_by(cut) %>%
  arrange(desc(price)) %>%
  slice(1:2) %>%
  ungroup() # 원래의 티블로 돌아와!
class(df_group)
```

또, `dplyr` 패키지는 `count()` 함수도 제공한다. 이 함수는 데이터의 특정 변수값에 기초해 그 집단 수를 세어 준다. 보통 분류형 변수에 많이 사용되지만 숫자형도 적용된다. 얘를 들어 1부터 2만에 이르는 범주를 가지는 변수가 총 50만개의 관측치를 가지고 있다고 할 때, 1의 값은 몇 개, 15는 몇 개, 2만은 몇 개와 같은 식으로 범주화를 시켜주는 것이다.

```{r}
df %>% count(cut)
## count()함수를 group_by() 함수로 바꾸어서 표현하면 아래와 같다.
df %>% group_by(cut) %>% summarise(n = n())

## group_by() 함수는 summarise() 함수와 결합될 경우 다양한 응용이 가능하다.
## 여기서 summarise는 총계를 구하라는 것이 아니라 데이터를 요약정리해서 보여줄 수 있는
## 여러 함수들을 통칭하는 것이다.
df %>%
  group_by(cut) %>%
  summarise(price_mean = mean(price)) # 컷팅 유형별로 평균 가격을 계산하라.
```

마찬가지로 `summarise()` 함수도 `_if, _at, _all`과 같은 세부유형으로 분류하여 사용할 수 있다.

```{r}
## cut, x, y, z 변수만 df 티블에서 뽑아내어 cut 유형별로 그룹화. 그리고 각 컷팅유형 별로
## x, y, z의 평균을 구하라.
df %>%
  select(cut, x, y, z) %>%
  group_by(cut) %>%
  summarise_all(mean, na.rm = T)

## 평균에 더하여 중앙값, 최소값, 최대값도 구해보자. 
df %>% group_by(cut) %>%
  summarise_at(            # 특정한 변수인 x, y, z를 대상으로
    vars(x, y, z),         # list 뒤의 함수들을 적용하라.
    list(mean, median, min, max),
    na.rm = T)             # mean 등은 데이터에 결측치가 있으면 결측치를 반환하므로
                           # 결측치 제거(remove na)가 TRUE이도록 설정한다.

## 컷팅 유형별로 그룹화한 다음에 숫자형 변수들일 경우에만 평균을 계산하라.
df %>% group_by(cut) %>%
  summarise_if(is.numeric, mean, na.rm = T)

## 동일한 코드이지만 표현식이 조금 다르다.
df %>% group_by(cut) %>%
  summarise_if(is.numeric, function(x) mean(x, na.rm = T))

df %>% group_by(cut) %>%
  summarise_if(is.numeric, ~ mean(., na.rm = T))
```

## 데이터 결합하기(Join data)

연구를 진행하다보면 하나로 분석에 필요한 모든 변수가 포함된 데이터를 만나기란 하늘에 별 따기라는 것을 알 수 있다. 따라서 서로 다른 소스에서 필요한 변수들을 추출해 하나의 데이터로 구성하는, 데이터 결합 작업이 중요하다. 보통은 머징(merging)이라고도 많이 한다.

일단 미국의 주 이름 객체 반복추출(replacement)가 가능하도록 설정하고 총 250개의 관측치를 가지는 표본을 만들어보자. 변수명이 `state_name`인 티블을 하나 만들었다. 250의 관측치들은 미국의 각 주 이름이 중복되어 존재한다.

  + `sample()` 함수의 `replace = T` 옵션은 상자 안에서 공을 꺼낼 때, 한 번 꺼낸 공을 다시 집어넣고 다시 꺼낼 수 있다는 것을 의미한다.
  + 이렇게 반복추출된 `state_name` 변수는 미국 각 주의 이름이 무작위로 반복추출되어 총 250개의 관측치를 가지게 된다.

```{r}
states_df <- tibble(state_name = sample(state.name, 250, replace = T))
states_df %>% count(state_name)
```

이번에는 `state_name`와 미국 주 이름의 약자를 의미하는 `state_abb` 변수를 만들어보자. 즉, `states_table`은 미국의 50개 주의 이름과 약자의 두 변수를 가지고 있는 티블이다.

```{r}
states_table <- tibble(
  state_name = state.name, state_abb = state.abb
)
head(states_table)
```

자, 이제 250개의 관측치를 갖는 `state_df` 티블과 50개의 관측치 값을 갖는 `states_table` 티블을 결합해보자. 기준은 `left_join()`이므로 `states_df`가 된다. 따라서 우리는 `states_df`의 모든 관측치를 유지한 채로 `states_table`의 관측치를 옮겨 붙일 것이다.

```{r}
left_join(states_df, states_table) %>% print( n = 10 )
```

이게 가능한 이유는 두 티블 사이에 공통의 변수, `state_name`이 존재하기 때문이다. 이 경우는 자동으로 묶였지만 어떤 변수를 기준으로 그룹화할 것인지 지정해줄 수도 있다.

```{r}
left_join(states_df, states_table, by = 'state_name') %>% 
  print( n = 10 )
```

이외에도 `right_join(), inner_join(), full_join()`, 그리고 `anti_join()`과 같은 함수로 결합할 수도 있다. 자세한 내용은 `tidyverse` 패키지 중 [결합(join)에 관한 내용](https://dplyr.tidyverse.org/reference/join.html)에서 살펴볼 수 있다. 결합, 머징에 관한 내용은 추후 더 구체적으로 다루어볼 것이다.

일단 예시로 `anti_join()` 함수가 어떻게 쓰이는지 보자. `anti_join()`은 대개 텍스트 분석에서 사용된다.
```{r}
text_df <- tibble(
  text = c('the fox is brown and the dog is black and the rabbit is white')
)
library(tidytext)
text_df <- text_df %>%
  unnest_tokens(word, text) # text를 어절로 분해
text_df
text_df %>% anti_join(tidytext::stop_words, by = 'word') # 특정 어절은 제외하고 단어만.
```